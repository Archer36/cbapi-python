#!/usr/bin/env python
#
# The MIT License (MIT)
#
# Copyright (c) 2016 Carbon Black Inc.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
# -----------------------------------------------------------------------------
#
#  last updated 2016-04-07 by Jason McFarland
#
import sys
import os
import requests_cache

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), "../../")))
import optparse
import cbapi

import requests.packages.urllib3
requests.packages.urllib3.disable_warnings()


def large_process_search():
    processes = cb.process_search("", rows=100)
    print "[+]: Number of processes returned: %d" % len(processes.get('results'))

    for process in processes.get('results'):
        print "[+]: Retrieving Process summary for %s" % process['id']
        cb.process_summary(process['id'], process['segment_id'])
        print "[+]: Retrieving Process events for %s" % process['id']
        cb.process_events(process['id'], process['segment_id'])

        #
        # v2 endpoint testing
        #
        cb.cbapi_get(cbserverurl + '/api/v2/process/%s' % process['id'])
        cb.cbapi_get(cbserverurl + '/api/v2/process/%s/1/event' % process['id'])

def large_binary_search():
    binaries = cb.binary_search("", rows=100)
    print "[+]: Number of binaries returned: %d" % len(binaries.get('results'))

    for binary in binaries.get('results'):
        print "[+]: Retrieving binary summary for %s" % binary['md5']
        cb.binary_summary(binary['md5'])


def test_sensors():
    sensors = cb.sensors()
    print "[+]: Number of sensors returned: %d" % len(sensors)
    for sensor in sensors:
        print "[+]: Retrieving sensor info for sensor ID %s" % sensor['id']
        cb.sensor(sensor['id'])


def test_watchlist():
    watchlists = cb.watchlist()
    print "[+]: Number of watchlists returned: %d" % len(watchlists)
    for watchlist in watchlists:
        print "[+]: Retrieving Watchlist ID: %d" % int(watchlist['id'])
        cb.watchlist(watchlist['id'])


def test_feeds():
    feeds = cb.feed_enum()
    print "[+]: Number of feeds returned: %d" % len(feeds)
    for feed in feeds:
        print "[+]: Retrieving Feed ID: %d" % int(feed['id'])
        cb.feed_info(feed.get('id'))


def add_base_endpoints():
    pass

def test_base_endpoints():
    #
    # Generated by parsing api blueprint
    #
    cb.cbapi_get(cbserverurl + "/api/login-caps")
    cb.cbapi_get(cbserverurl + "/api/hostexport")
    cb.cbapi_get(cbserverurl + "/api/site")
    cb.cbapi_get(cbserverurl + "/api/v1/license")
    cb.cbapi_get(cbserverurl + "/api/license")
    cb.cbapi_get(cbserverurl + "/api/communication_settings")
    cb.cbapi_get(cbserverurl + "/api/v1/feed")
    cb.cbapi_get(cbserverurl + "/api/v1/threat_report")
    cb.cbapi_get(cbserverurl + "/api/v1/watchlist")
    cb.cbapi_get(cbserverurl + "/api/v1/dashboard/statistics")
    cb.cbapi_get(cbserverurl + "/api/v1/dashboard/hosts")
    cb.cbapi_get(cbserverurl + "/api/v1/dashboard/alliance")
    cb.cbapi_get(cbserverurl + "/api/notification")
    cb.cbapi_get(cbserverurl + "/api/investigations")
    cb.cbapi_get(cbserverurl + "/api/v1/sensor/statistics")
    cb.cbapi_get(cbserverurl + "/api/v1/sensor/version/latest")
    cb.cbapi_get(cbserverurl + "/api/builds")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/currentalertstatus")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/currentmonitoringstatus")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/unresolvedalerttrend/")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/unresolvedalertsbytime/")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/unresolvedalertsbyseverity/")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/unresolvedhostsbytime/")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/unresolvedhostsbyseverity/")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/unresolvedusersbytime/")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/unresolvedusersbyseverity/")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/alertresolutionaverage/")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/binarydwell/")
    cb.cbapi_get(cbserverurl + "/api/v1/detect/report/hosthygiene/")
    cb.cbapi_get(cbserverurl + "/api/v1/banning/blacklist")
    cb.cbapi_get(cbserverurl + "/api/v1/banning/whitelist")
    cb.cbapi_get(cbserverurl + "/api/v1/banning/restrictions")

def main(argv):
    parser = build_cli_parser()
    opts, args = parser.parse_args(argv)
    if not opts.url or not opts.token:
        parser.print_help()
        sys.exit(-1)

    global cache_file_name
    cache_file_name = opts.cache_name
    requests_cache.install_cache(cache_file_name, allowable_methods=('GET', 'POST'))

    global cbserverurl
    cbserverurl = opts.url

    #
    # build a cbapi object
    #
    global cb
    cb = cbapi.CbApi(opts.url, token=opts.token, ssl_verify=opts.ssl_verify)

    #
    # Run Tests to get cached responses
    #
    large_process_search()

    large_binary_search()

    test_sensors()

    test_watchlist()

    test_base_endpoints()

    test_feeds()

    cache = requests_cache.get_cache()

def build_cli_parser():
    parser = optparse.OptionParser(usage="%prog [options]",
                                   description="Create a cache of responses for regression testing")

    #
    # for each supported output type, add an option
    #
    parser.add_option("-c", "--cburl", action="store", default=None, dest="url",
                      help="CB server's URL.  e.g., http://127.0.0.1 ")
    parser.add_option("-a", "--apitoken", action="store", default=None, dest="token",
                      help="API Token for Carbon Black server")
    parser.add_option("-n", "--no-ssl-verify", action="store_false", default=True, dest="ssl_verify",
                      help="Do not verify server SSL certificate.")
    parser.add_option("-f", "--cache", action="store", default="cache", dest="cache_name",
                      help="Cache sqlite file name")
    return parser


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
